{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook written by [Zhedong Zheng](https://github.com/zhedongzheng)\n",
    "\n",
    "![title](ctc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pip3 install librosa\n",
    "pip3 install bs4\n",
    "\"\"\"\n",
    "\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'num_epochs': 50,\n",
    "    'batch_size': 30,\n",
    "    'rnn_size': 20,\n",
    "    'clip_norm': 5.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download():\n",
    "    prefix = 'https://tspace.library.utoronto.ca'\n",
    "    save_dir = './data/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    base_url = 'https://tspace.library.utoronto.ca/handle/1807/24'\n",
    "    urls = [base_url+str(i) for i in range(488, 502)]\n",
    "\n",
    "    for url in urls:\n",
    "        soup = BeautifulSoup(urlopen(url).read(), 'html5lib')\n",
    "        targets = soup.findAll('a', href=re.compile(r'/bitstream/.*.wav'))\n",
    "        \n",
    "        for a in tqdm(targets, total=len(targets), ncols=70):\n",
    "            link = a['href']\n",
    "\n",
    "            audio_save_loc = save_dir + link.split('/')[-1]\n",
    "            if os.path.isfile(audio_save_loc):\n",
    "                print(\"File Already Exists\")\n",
    "            urlretrieve(prefix+a['href'], audio_save_loc)\n",
    "\n",
    "            with open(audio_save_loc.replace('.wav', '.txt'), 'w') as f:\n",
    "                f.write('say the word ' + link.split('_')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_tuple_from(sequences, dtype=np.int32):\n",
    "    \"\"\"Create a sparse representention of x.\n",
    "    Args:\n",
    "        sequences: a list of lists of type dtype where each element is a sequence\n",
    "    Returns:\n",
    "        A tuple with (indices, values, shape)\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for n, seq in enumerate(sequences):\n",
    "        indices.extend(zip([n]*len(seq), range(len(seq))))\n",
    "        values.extend(seq)\n",
    "\n",
    "    indices = np.asarray(indices, dtype=np.int64)\n",
    "    values = np.asarray(values, dtype=dtype)\n",
    "    shape = np.asarray([len(sequences), np.asarray(indices).max(0)[1]+1], dtype=np.int64)\n",
    "\n",
    "    return (indices, values, shape)\n",
    "\n",
    "\n",
    "def train_input_fn(X, y):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    dataset = dataset.shuffle(10000).batch(PARAMS['batch_size']).repeat(PARAMS['num_epochs'])\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    return iterator.get_next()\n",
    "\n",
    "\n",
    "def rnn_cell():\n",
    "    return tf.nn.rnn_cell.GRUCell(PARAMS['rnn_size'],\n",
    "        kernel_initializer=tf.orthogonal_initializer())\n",
    "\n",
    "\n",
    "def clip_grads(loss_op):\n",
    "    variables = tf.trainable_variables()\n",
    "    grads = tf.gradients(loss_op, variables)\n",
    "    clipped_grads, _ = tf.clip_by_global_norm(grads, PARAMS['clip_norm'])\n",
    "    return zip(clipped_grads, variables)\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    seq_lens = tf.count_nonzero(tf.reduce_sum(features, -1), 1, dtype=tf.int32)\n",
    "    \n",
    "    outputs, _ = tf.nn.bidirectional_dynamic_rnn(\n",
    "        rnn_cell(), rnn_cell(), features, seq_lens, dtype=tf.float32)\n",
    "    outputs = tf.concat(outputs, -1)\n",
    "    logits = tf.layers.dense(outputs, PARAMS['num_classes'])\n",
    "    \n",
    "    time_major = tf.transpose(logits, [1,0,2])\n",
    "    decoded, log_prob = tf.nn.ctc_greedy_decoder(time_major, seq_lens)\n",
    "    decoded = tf.to_int32(decoded[0])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        preds = tf.sparse_tensor_to_dense(decoded)\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=preds)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        loss_op = tf.reduce_mean(tf.nn.ctc_loss(labels, time_major, seq_lens))\n",
    "        edit_dist_op = tf.reduce_mean(tf.edit_distance(decoded, labels))\n",
    "\n",
    "        lth = tf.train.LoggingTensorHook({'edit_dist': edit_dist_op}, every_n_iter=100)\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer().apply_gradients(\n",
    "            clip_grads(loss_op), global_step=tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=loss_op, train_op=train_op, training_hooks=[lth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 200/200 [02:13<00:00,  1.50it/s]\n",
      "100%|███████████████████████████████| 200/200 [02:05<00:00,  1.59it/s]\n",
      "100%|███████████████████████████████| 200/200 [02:17<00:00,  1.46it/s]\n",
      "100%|███████████████████████████████| 200/200 [02:15<00:00,  1.48it/s]\n",
      "100%|███████████████████████████████| 200/200 [02:02<00:00,  1.64it/s]\n",
      "100%|███████████████████████████████| 200/200 [02:13<00:00,  1.50it/s]\n",
      "100%|███████████████████████████████| 200/200 [02:21<00:00,  1.41it/s]\n",
      "100%|███████████████████████████████| 200/200 [02:32<00:00,  1.31it/s]\n",
      "100%|███████████████████████████████| 200/200 [03:07<00:00,  1.07it/s]\n",
      "100%|███████████████████████████████| 200/200 [03:25<00:00,  1.03s/it]\n",
      "100%|███████████████████████████████| 200/200 [03:26<00:00,  1.03s/it]\n",
      "100%|███████████████████████████████| 200/200 [02:41<00:00,  1.24it/s]\n",
      "100%|███████████████████████████████| 200/200 [03:12<00:00,  1.04it/s]\n",
      "100%|███████████████████████████████| 200/200 [03:01<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 2800/2800 [02:34<00:00, 18.09it/s]\n"
     ]
    }
   ],
   "source": [
    "wav_files = [f for f in os.listdir('./data') if f.endswith('.wav')]\n",
    "text_files = [f for f in os.listdir('./data') if f.endswith('.txt')]\n",
    "\n",
    "inputs, targets = [], []\n",
    "for (wav_file, text_file) in tqdm(zip(wav_files, text_files), total=len(wav_files), ncols=70):\n",
    "    path = './data/' + wav_file\n",
    "    try:\n",
    "        y, sr = librosa.load(path)\n",
    "    except:\n",
    "        continue\n",
    "    _input = librosa.feature.mfcc(y, sr).T\n",
    "    inputs.append(_input)\n",
    "    with open('./data/'+text_file) as f:\n",
    "        targets.append(f.read())\n",
    "\n",
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    inputs, dtype='float32', padding='post')\n",
    "\n",
    "chars = list(set([c for target in targets for c in target]))\n",
    "PARAMS['num_classes'] = len(chars) + 1\n",
    "\n",
    "idx2char = {idx: char for idx, char in enumerate(chars)}\n",
    "char2idx = {char: idx for idx, char in idx2char.items()}\n",
    "\n",
    "targets = [[char2idx[c] for c in target] for target in targets]\n",
    "\n",
    "inputs_val = np.expand_dims(inputs[-1], 0)\n",
    "targets_val = targets[-1]\n",
    "\n",
    "inputs_train = inputs[:-1]\n",
    "targets_train = targets[:-1]\n",
    "targets_train = tf.SparseTensor(*sparse_tuple_from(targets_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpe3auswoa\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpe3auswoa', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11b9ed780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x119cea9d8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpe3auswoa/model.ckpt.\n",
      "INFO:tensorflow:loss = 179.03998, step = 1\n",
      "INFO:tensorflow:edit_dist = 1.1491777\n",
      "INFO:tensorflow:global_step/sec: 15.0124\n",
      "INFO:tensorflow:loss = 64.49377, step = 101 (6.663 sec)\n",
      "INFO:tensorflow:edit_dist = 0.94205654 (6.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5816\n",
      "INFO:tensorflow:loss = 53.693245, step = 201 (6.030 sec)\n",
      "INFO:tensorflow:edit_dist = 0.8734341 (6.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7135\n",
      "INFO:tensorflow:loss = 49.68438, step = 301 (6.364 sec)\n",
      "INFO:tensorflow:edit_dist = 0.80785674 (6.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3239\n",
      "INFO:tensorflow:loss = 48.89897, step = 401 (6.526 sec)\n",
      "INFO:tensorflow:edit_dist = 0.76245916 (6.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.3114\n",
      "INFO:tensorflow:loss = 47.344337, step = 501 (6.531 sec)\n",
      "INFO:tensorflow:edit_dist = 0.7437557 (6.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8317\n",
      "INFO:tensorflow:loss = 45.79742, step = 601 (6.316 sec)\n",
      "INFO:tensorflow:edit_dist = 0.73155427 (6.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 14.8577\n",
      "INFO:tensorflow:loss = 43.58013, step = 701 (6.730 sec)\n",
      "INFO:tensorflow:edit_dist = 0.6762068 (6.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.2776\n",
      "INFO:tensorflow:loss = 40.3881, step = 801 (6.546 sec)\n",
      "INFO:tensorflow:edit_dist = 0.67816985 (6.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7831\n",
      "INFO:tensorflow:loss = 40.082058, step = 901 (6.336 sec)\n",
      "INFO:tensorflow:edit_dist = 0.6551879 (6.336 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6768\n",
      "INFO:tensorflow:loss = 40.407337, step = 1001 (6.379 sec)\n",
      "INFO:tensorflow:edit_dist = 0.67913944 (6.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0975\n",
      "INFO:tensorflow:loss = 37.946613, step = 1101 (6.212 sec)\n",
      "INFO:tensorflow:edit_dist = 0.64054006 (6.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2078\n",
      "INFO:tensorflow:loss = 36.705956, step = 1201 (6.170 sec)\n",
      "INFO:tensorflow:edit_dist = 0.6444323 (6.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3606\n",
      "INFO:tensorflow:loss = 36.158054, step = 1301 (6.112 sec)\n",
      "INFO:tensorflow:edit_dist = 0.6066177 (6.112 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.5995\n",
      "INFO:tensorflow:loss = 36.915268, step = 1401 (6.024 sec)\n",
      "INFO:tensorflow:edit_dist = 0.6148693 (6.024 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2539\n",
      "INFO:tensorflow:loss = 36.18281, step = 1501 (6.153 sec)\n",
      "INFO:tensorflow:edit_dist = 0.59832865 (6.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1291\n",
      "INFO:tensorflow:loss = 35.473797, step = 1601 (6.200 sec)\n",
      "INFO:tensorflow:edit_dist = 0.6023938 (6.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.9782\n",
      "INFO:tensorflow:loss = 35.683884, step = 1701 (5.890 sec)\n",
      "INFO:tensorflow:edit_dist = 0.58224815 (5.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.026\n",
      "INFO:tensorflow:loss = 35.622173, step = 1801 (6.240 sec)\n",
      "INFO:tensorflow:edit_dist = 0.5905728 (6.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6161\n",
      "INFO:tensorflow:loss = 33.290173, step = 1901 (6.404 sec)\n",
      "INFO:tensorflow:edit_dist = 0.5792048 (6.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6736\n",
      "INFO:tensorflow:loss = 33.324482, step = 2001 (6.380 sec)\n",
      "INFO:tensorflow:edit_dist = 0.5665004 (6.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1232\n",
      "INFO:tensorflow:loss = 30.851877, step = 2101 (6.202 sec)\n",
      "INFO:tensorflow:edit_dist = 0.53956974 (6.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8836\n",
      "INFO:tensorflow:loss = 32.828323, step = 2201 (6.296 sec)\n",
      "INFO:tensorflow:edit_dist = 0.5627768 (6.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3155\n",
      "INFO:tensorflow:loss = 32.66302, step = 2301 (6.129 sec)\n",
      "INFO:tensorflow:edit_dist = 0.55688566 (6.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0217\n",
      "INFO:tensorflow:loss = 31.578999, step = 2401 (6.242 sec)\n",
      "INFO:tensorflow:edit_dist = 0.5105365 (6.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9165\n",
      "INFO:tensorflow:loss = 33.274002, step = 2501 (6.283 sec)\n",
      "INFO:tensorflow:edit_dist = 0.53874487 (6.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0554\n",
      "INFO:tensorflow:loss = 30.554724, step = 2601 (6.228 sec)\n",
      "INFO:tensorflow:edit_dist = 0.53146785 (6.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0194\n",
      "INFO:tensorflow:loss = 30.290771, step = 2701 (6.243 sec)\n",
      "INFO:tensorflow:edit_dist = 0.50362206 (6.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1654\n",
      "INFO:tensorflow:loss = 32.123173, step = 2801 (6.186 sec)\n",
      "INFO:tensorflow:edit_dist = 0.5218696 (6.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.1155\n",
      "INFO:tensorflow:loss = 30.417913, step = 2901 (6.206 sec)\n",
      "INFO:tensorflow:edit_dist = 0.49977428 (6.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2359\n",
      "INFO:tensorflow:loss = 29.394247, step = 3001 (6.159 sec)\n",
      "INFO:tensorflow:edit_dist = 0.49657652 (6.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9586\n",
      "INFO:tensorflow:loss = 31.755741, step = 3101 (6.266 sec)\n",
      "INFO:tensorflow:edit_dist = 0.4932734 (6.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8308\n",
      "INFO:tensorflow:loss = 31.278067, step = 3201 (6.317 sec)\n",
      "INFO:tensorflow:edit_dist = 0.497744 (6.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.7564\n",
      "INFO:tensorflow:loss = 29.865395, step = 3301 (6.347 sec)\n",
      "INFO:tensorflow:edit_dist = 0.4676951 (6.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9254\n",
      "INFO:tensorflow:loss = 28.502264, step = 3401 (6.279 sec)\n",
      "INFO:tensorflow:edit_dist = 0.44223458 (6.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.4582\n",
      "INFO:tensorflow:loss = 27.09485, step = 3501 (6.469 sec)\n",
      "INFO:tensorflow:edit_dist = 0.49858388 (6.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0913\n",
      "INFO:tensorflow:loss = 26.236908, step = 3601 (6.214 sec)\n",
      "INFO:tensorflow:edit_dist = 0.4467729 (6.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3836\n",
      "INFO:tensorflow:loss = 27.96038, step = 3701 (6.104 sec)\n",
      "INFO:tensorflow:edit_dist = 0.44565848 (6.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5661\n",
      "INFO:tensorflow:loss = 25.654682, step = 3801 (6.424 sec)\n",
      "INFO:tensorflow:edit_dist = 0.46575794 (6.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.5452\n",
      "INFO:tensorflow:loss = 26.08488, step = 3901 (6.433 sec)\n",
      "INFO:tensorflow:edit_dist = 0.4364709 (6.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.3376\n",
      "INFO:tensorflow:loss = 25.816992, step = 4001 (6.121 sec)\n",
      "INFO:tensorflow:edit_dist = 0.4468001 (6.121 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.8347\n",
      "INFO:tensorflow:loss = 24.56371, step = 4101 (6.315 sec)\n",
      "INFO:tensorflow:edit_dist = 0.42761436 (6.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9258\n",
      "INFO:tensorflow:loss = 25.050037, step = 4201 (6.279 sec)\n",
      "INFO:tensorflow:edit_dist = 0.4064937 (6.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9824\n",
      "INFO:tensorflow:loss = 23.927893, step = 4301 (6.257 sec)\n",
      "INFO:tensorflow:edit_dist = 0.39354575 (6.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.9421\n",
      "INFO:tensorflow:loss = 24.416775, step = 4401 (6.273 sec)\n",
      "INFO:tensorflow:edit_dist = 0.4219793 (6.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0205\n",
      "INFO:tensorflow:loss = 25.402779, step = 4501 (6.242 sec)\n",
      "INFO:tensorflow:edit_dist = 0.40344742 (6.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.4676\n",
      "INFO:tensorflow:loss = 24.319044, step = 4601 (6.073 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:edit_dist = 0.39746732 (6.073 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4700 into /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpe3auswoa/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 24.88604.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpe3auswoa/model.ckpt-4700\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction: say the \n",
      "Actual: say the word youth\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn)\n",
    "\n",
    "estimator.train(lambda: train_input_fn(inputs_train, targets_train))\n",
    "\n",
    "preds = list(estimator.predict(tf.estimator.inputs.numpy_input_fn(inputs_val, shuffle=False)))\n",
    "\n",
    "print('Prediction:', ''.join([idx2char[idx] for idx in preds[0]]))\n",
    "print('Actual:', ''.join([idx2char[idx] for idx in targets_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
