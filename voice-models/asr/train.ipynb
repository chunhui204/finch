{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook written by [Zhedong Zheng](https://github.com/zhedongzheng)\n",
    "\n",
    "![title](ctc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pip3 install librosa\n",
    "pip3 install bs4\n",
    "\"\"\"\n",
    "\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'num_epochs': 50,\n",
    "    'batch_size': 30,\n",
    "    'clip_norm': 5.0,\n",
    "    'winstep': 0.01,\n",
    "    'n_mfcc': 39,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download():\n",
    "    prefix = 'https://tspace.library.utoronto.ca'\n",
    "    save_dir = './data/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    base_url = 'https://tspace.library.utoronto.ca/handle/1807/24'\n",
    "    urls = [base_url+str(i) for i in range(488, 502)]\n",
    "\n",
    "    for url in urls:\n",
    "        soup = BeautifulSoup(urlopen(url).read(), 'html5lib')\n",
    "        targets = soup.findAll('a', href=re.compile(r'/bitstream/.*.wav'))\n",
    "        \n",
    "        for a in tqdm(targets, total=len(targets), ncols=70):\n",
    "            link = a['href']\n",
    "\n",
    "            audio_save_loc = save_dir + link.split('/')[-1]\n",
    "            if os.path.isfile(audio_save_loc):\n",
    "                print(\"File Already Exists\")\n",
    "            urlretrieve(prefix+a['href'], audio_save_loc)\n",
    "\n",
    "            with open(audio_save_loc.replace('.wav', '.txt'), 'w') as f:\n",
    "                f.write('say the word ' + link.split('_')[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_tuple_from(sequences, dtype=np.int32):\n",
    "    \"\"\"Create a sparse representention of x.\n",
    "    Args:\n",
    "        sequences: a list of lists of type dtype where each element is a sequence\n",
    "    Returns:\n",
    "        A tuple with (indices, values, shape)\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for n, seq in enumerate(sequences):\n",
    "        indices.extend(zip([n]*len(seq), range(len(seq))))\n",
    "        values.extend(seq)\n",
    "\n",
    "    indices = np.asarray(indices, dtype=np.int64)\n",
    "    values = np.asarray(values, dtype=dtype)\n",
    "    shape = np.asarray([len(sequences), np.asarray(indices).max(0)[1]+1], dtype=np.int64)\n",
    "\n",
    "    return (indices, values, shape)\n",
    "\n",
    "\n",
    "def train_input_fn(X, y):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    dataset = dataset.shuffle(10000).batch(PARAMS['batch_size']).repeat(PARAMS['num_epochs'])\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    return iterator.get_next()\n",
    "\n",
    "\n",
    "def rnn_cell():\n",
    "    return tf.nn.rnn_cell.GRUCell(PARAMS['n_mfcc'],\n",
    "        kernel_initializer=tf.orthogonal_initializer())\n",
    "\n",
    "\n",
    "def clip_grads(loss_op):\n",
    "    variables = tf.trainable_variables()\n",
    "    grads = tf.gradients(loss_op, variables)\n",
    "    clipped_grads, _ = tf.clip_by_global_norm(grads, PARAMS['clip_norm'])\n",
    "    return zip(clipped_grads, variables)\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "    seq_lens = tf.count_nonzero(tf.reduce_sum(features, -1), 1, dtype=tf.int32)\n",
    "    \n",
    "    outputs, _ = tf.nn.bidirectional_dynamic_rnn(\n",
    "        rnn_cell(), rnn_cell(), features, seq_lens, dtype=tf.float32)\n",
    "    outputs = tf.concat(outputs, -1)\n",
    "    logits = tf.layers.dense(outputs, PARAMS['num_classes'])\n",
    "    \n",
    "    time_major = tf.transpose(logits, [1,0,2])\n",
    "    decoded, log_prob = tf.nn.ctc_greedy_decoder(time_major, seq_lens)\n",
    "    decoded = tf.to_int32(decoded[0])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        preds = tf.sparse_tensor_to_dense(decoded)\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=preds)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        loss_op = tf.reduce_mean(tf.nn.ctc_loss(labels, time_major, seq_lens))\n",
    "        edit_dist_op = tf.reduce_mean(tf.edit_distance(decoded, labels))\n",
    "\n",
    "        lth = tf.train.LoggingTensorHook({'edit_dist': edit_dist_op}, every_n_iter=100)\n",
    "        \n",
    "        train_op = tf.train.AdamOptimizer().apply_gradients(\n",
    "            clip_grads(loss_op), global_step=tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode=mode, loss=loss_op, train_op=train_op, training_hooks=[lth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 200/200 [02:10<00:00,  1.53it/s]\n",
      "100%|███████████████████████████████| 200/200 [02:46<00:00,  1.20it/s]\n",
      "100%|███████████████████████████████| 200/200 [03:05<00:00,  1.08it/s]\n",
      "100%|███████████████████████████████| 200/200 [03:03<00:00,  1.09it/s]\n",
      "100%|███████████████████████████████| 200/200 [02:44<00:00,  1.21it/s]\n",
      "100%|███████████████████████████████| 200/200 [02:59<00:00,  1.11it/s]\n",
      "100%|███████████████████████████████| 200/200 [03:17<00:00,  1.01it/s]\n",
      "100%|███████████████████████████████| 200/200 [03:01<00:00,  1.10it/s]\n",
      "100%|███████████████████████████████| 200/200 [03:06<00:00,  1.07it/s]\n",
      "100%|███████████████████████████████| 200/200 [03:24<00:00,  1.02s/it]\n",
      "100%|███████████████████████████████| 200/200 [03:23<00:00,  1.02s/it]\n",
      "100%|███████████████████████████████| 200/200 [02:44<00:00,  1.22it/s]\n",
      "100%|███████████████████████████████| 200/200 [03:12<00:00,  1.04it/s]\n",
      "100%|███████████████████████████████| 200/200 [03:02<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 2800/2800 [01:03<00:00, 44.17it/s]\n"
     ]
    }
   ],
   "source": [
    "wav_files = [f for f in os.listdir('./data') if f.endswith('.wav')]\n",
    "text_files = [f for f in os.listdir('./data') if f.endswith('.txt')]\n",
    "\n",
    "inputs, targets = [], []\n",
    "for (wav_file, text_file) in tqdm(zip(wav_files, text_files), total=len(wav_files), ncols=70):\n",
    "    path = './data/' + wav_file\n",
    "    try:\n",
    "        y, sr = librosa.load(path, sr=None)\n",
    "    except:\n",
    "        continue\n",
    "    inputs.append(librosa.feature.mfcc(y = y,\n",
    "                                       sr = sr,\n",
    "                                       n_mfcc = PARAMS['n_mfcc'],\n",
    "                                       hop_length = int(PARAMS['winstep']*sr)).T)\n",
    "    with open('./data/'+text_file) as f:\n",
    "        targets.append(f.read())\n",
    "\n",
    "inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    inputs, dtype='float32', padding='post')\n",
    "\n",
    "chars = list(set([c for target in targets for c in target]))\n",
    "PARAMS['num_classes'] = len(chars) + 1\n",
    "\n",
    "idx2char = {idx: char for idx, char in enumerate(chars)}\n",
    "char2idx = {char: idx for idx, char in idx2char.items()}\n",
    "\n",
    "targets = [[char2idx[c] for c in target] for target in targets]\n",
    "\n",
    "inputs_val = np.expand_dims(inputs[-1], 0)\n",
    "targets_val = targets[-1]\n",
    "\n",
    "inputs_train = inputs[:-1]\n",
    "targets_train = targets[:-1]\n",
    "targets_train = tf.SparseTensor(*sparse_tuple_from(targets_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpxg9xalhy\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpxg9xalhy', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x119938b38>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x1179389d8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpxg9xalhy/model.ckpt.\n",
      "INFO:tensorflow:loss = 507.17838, step = 1\n",
      "INFO:tensorflow:edit_dist = 2.1075466\n",
      "INFO:tensorflow:global_step/sec: 5.62451\n",
      "INFO:tensorflow:loss = 54.262714, step = 101 (17.780 sec)\n",
      "INFO:tensorflow:edit_dist = 0.9421432 (17.780 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.22801\n",
      "INFO:tensorflow:loss = 46.681538, step = 201 (16.056 sec)\n",
      "INFO:tensorflow:edit_dist = 0.8394608 (16.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05085\n",
      "INFO:tensorflow:loss = 41.77193, step = 301 (16.526 sec)\n",
      "INFO:tensorflow:edit_dist = 0.8163599 (16.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.0761\n",
      "INFO:tensorflow:loss = 39.823586, step = 401 (16.458 sec)\n",
      "INFO:tensorflow:edit_dist = 0.793682 (16.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.32602\n",
      "INFO:tensorflow:loss = 39.236843, step = 501 (15.807 sec)\n",
      "INFO:tensorflow:edit_dist = 0.7526306 (15.808 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.05874\n",
      "INFO:tensorflow:loss = 36.139458, step = 601 (16.505 sec)\n",
      "INFO:tensorflow:edit_dist = 0.7318219 (16.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23207\n",
      "INFO:tensorflow:loss = 34.236862, step = 701 (16.046 sec)\n",
      "INFO:tensorflow:edit_dist = 0.71340233 (16.046 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.95874\n",
      "INFO:tensorflow:loss = 35.60837, step = 801 (16.782 sec)\n",
      "INFO:tensorflow:edit_dist = 0.70550114 (16.782 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.01953\n",
      "INFO:tensorflow:loss = 32.729763, step = 901 (16.613 sec)\n",
      "INFO:tensorflow:edit_dist = 0.6580173 (16.613 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.92805\n",
      "INFO:tensorflow:loss = 31.48532, step = 1001 (16.869 sec)\n",
      "INFO:tensorflow:edit_dist = 0.6419662 (16.869 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.23597\n",
      "INFO:tensorflow:loss = 33.65532, step = 1101 (16.036 sec)\n",
      "INFO:tensorflow:edit_dist = 0.6135592 (16.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.93239\n",
      "INFO:tensorflow:loss = 31.799822, step = 1201 (16.857 sec)\n",
      "INFO:tensorflow:edit_dist = 0.62848586 (16.857 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.98133\n",
      "INFO:tensorflow:loss = 30.167803, step = 1301 (20.076 sec)\n",
      "INFO:tensorflow:edit_dist = 0.5932734 (20.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.27206\n",
      "INFO:tensorflow:loss = 29.280256, step = 1401 (23.408 sec)\n",
      "INFO:tensorflow:edit_dist = 0.51608115 (23.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.01594\n",
      "INFO:tensorflow:loss = 28.739025, step = 1501 (24.901 sec)\n",
      "INFO:tensorflow:edit_dist = 0.57853466 (24.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.97037\n",
      "INFO:tensorflow:loss = 28.215815, step = 1601 (25.188 sec)\n",
      "INFO:tensorflow:edit_dist = 0.53808695 (25.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.11715\n",
      "INFO:tensorflow:loss = 28.413916, step = 1701 (24.287 sec)\n",
      "INFO:tensorflow:edit_dist = 0.5418337 (24.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.12727\n",
      "INFO:tensorflow:loss = 27.229338, step = 1801 (24.229 sec)\n",
      "INFO:tensorflow:edit_dist = 0.5185049 (24.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.30918\n",
      "INFO:tensorflow:loss = 26.461836, step = 1901 (23.206 sec)\n",
      "INFO:tensorflow:edit_dist = 0.497769 (23.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24559\n",
      "INFO:tensorflow:loss = 25.899364, step = 2001 (23.553 sec)\n",
      "INFO:tensorflow:edit_dist = 0.49892431 (23.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.33396\n",
      "INFO:tensorflow:loss = 26.024553, step = 2101 (23.074 sec)\n",
      "INFO:tensorflow:edit_dist = 0.4452206 (23.075 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.21659\n",
      "INFO:tensorflow:loss = 24.099115, step = 2201 (23.717 sec)\n",
      "INFO:tensorflow:edit_dist = 0.45348588 (23.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.94446\n",
      "INFO:tensorflow:loss = 25.125793, step = 2301 (25.351 sec)\n",
      "INFO:tensorflow:edit_dist = 0.45536134 (25.351 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.83069\n",
      "INFO:tensorflow:loss = 24.354767, step = 2401 (26.105 sec)\n",
      "INFO:tensorflow:edit_dist = 0.4459695 (26.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.79305\n",
      "INFO:tensorflow:loss = 25.703787, step = 2501 (26.364 sec)\n",
      "INFO:tensorflow:edit_dist = 0.41359794 (26.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.71421\n",
      "INFO:tensorflow:loss = 22.744322, step = 2601 (26.924 sec)\n",
      "INFO:tensorflow:edit_dist = 0.41078433 (26.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.09049\n",
      "INFO:tensorflow:loss = 24.07168, step = 2701 (24.447 sec)\n",
      "INFO:tensorflow:edit_dist = 0.45753428 (24.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.28188\n",
      "INFO:tensorflow:loss = 21.79858, step = 2801 (23.354 sec)\n",
      "INFO:tensorflow:edit_dist = 0.39709967 (23.353 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2843 into /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpxg9xalhy/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 3.28805\n",
      "INFO:tensorflow:loss = 22.72724, step = 2901 (30.413 sec)\n",
      "INFO:tensorflow:edit_dist = 0.40377182 (30.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.87217\n",
      "INFO:tensorflow:loss = 22.333515, step = 3001 (25.826 sec)\n",
      "INFO:tensorflow:edit_dist = 0.37975076 (25.825 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.7069\n",
      "INFO:tensorflow:loss = 22.733778, step = 3101 (26.978 sec)\n",
      "INFO:tensorflow:edit_dist = 0.41441423 (26.980 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.84903\n",
      "INFO:tensorflow:loss = 23.867949, step = 3201 (25.978 sec)\n",
      "INFO:tensorflow:edit_dist = 0.37793934 (25.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.81275\n",
      "INFO:tensorflow:loss = 22.075115, step = 3301 (26.228 sec)\n",
      "INFO:tensorflow:edit_dist = 0.36245918 (26.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.92306\n",
      "INFO:tensorflow:loss = 20.563295, step = 3401 (25.490 sec)\n",
      "INFO:tensorflow:edit_dist = 0.34798476 (25.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.87668\n",
      "INFO:tensorflow:loss = 21.513302, step = 3501 (25.795 sec)\n",
      "INFO:tensorflow:edit_dist = 0.35948932 (25.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.00593\n",
      "INFO:tensorflow:loss = 20.1493, step = 3601 (24.963 sec)\n",
      "INFO:tensorflow:edit_dist = 0.34527218 (24.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.11887\n",
      "INFO:tensorflow:loss = 18.996767, step = 3701 (24.279 sec)\n",
      "INFO:tensorflow:edit_dist = 0.35014978 (24.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.69371\n",
      "INFO:tensorflow:loss = 20.87769, step = 3801 (27.073 sec)\n",
      "INFO:tensorflow:edit_dist = 0.35923347 (27.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.77347\n",
      "INFO:tensorflow:loss = 20.737797, step = 3901 (26.502 sec)\n",
      "INFO:tensorflow:edit_dist = 0.36162713 (26.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.83126\n",
      "INFO:tensorflow:loss = 20.025429, step = 4001 (26.103 sec)\n",
      "INFO:tensorflow:edit_dist = 0.30524036 (26.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.74025\n",
      "INFO:tensorflow:loss = 19.726343, step = 4101 (26.733 sec)\n",
      "INFO:tensorflow:edit_dist = 0.30229047 (26.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.36474\n",
      "INFO:tensorflow:loss = 19.270626, step = 4201 (22.911 sec)\n",
      "INFO:tensorflow:edit_dist = 0.32813036 (22.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.23511\n",
      "INFO:tensorflow:loss = 22.66853, step = 4301 (23.612 sec)\n",
      "INFO:tensorflow:edit_dist = 0.32709697 (23.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.24414\n",
      "INFO:tensorflow:loss = 19.234554, step = 4401 (23.563 sec)\n",
      "INFO:tensorflow:edit_dist = 0.32612875 (23.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.29307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 19.196615, step = 4501 (23.293 sec)\n",
      "INFO:tensorflow:edit_dist = 0.32155505 (23.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.17865\n",
      "INFO:tensorflow:loss = 20.466366, step = 4601 (19.310 sec)\n",
      "INFO:tensorflow:edit_dist = 0.35303077 (19.310 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4700 into /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpxg9xalhy/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 16.368826.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/sx/fv0r97j96fz8njp14dt5g7940000gn/T/tmpxg9xalhy/model.ckpt-4700\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction: say the word \n",
      "Actual: say the word youth\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn)\n",
    "\n",
    "estimator.train(lambda: train_input_fn(inputs_train, targets_train))\n",
    "\n",
    "preds = list(estimator.predict(tf.estimator.inputs.numpy_input_fn(inputs_val, shuffle=False)))\n",
    "\n",
    "print('Prediction:', ''.join([idx2char[idx] for idx in preds[0]]))\n",
    "print('Actual:', ''.join([idx2char[idx] for idx in targets_val]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
